{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tumor_Classifier_Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in data\n",
    "train, train_y, val, val_y, test, test_y, N, num_classes = load_data(64)\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)\n",
    "print(train_y.shape)\n",
    "print(val_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_PCA = np.reshape(train[:,:,:,:], (2500, -1))\n",
    "val_PCA = np.reshape(val[:,:,:,:], (500, -1))\n",
    "test_PCA = np.reshape(test[:,:,:,:], (264, -1))\n",
    "\n",
    "print(train_PCA.shape)\n",
    "print(val_PCA.shape)\n",
    "print(test_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "pca.fit(train_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20, 8])\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(4, 5, i + 1)\n",
    "    pc = np.reshape(pca.components_[i*10,:], (N, N)) \n",
    "    ax.imshow(pc)\n",
    "    ax.set_title(\"PCA Components: \" + str(i*10))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train = pca.transform(train_PCA)\n",
    "transformed_val = pca.transform(val_PCA)\n",
    "transformed_test = pca.transform(test_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_sum = np.cumsum(pca.explained_variance_ratio_, axis=0)\n",
    "top90 = np.where(cumulative_sum > 0.90)[0][0]\n",
    "top95 = np.where(cumulative_sum > 0.95)[0][0]\n",
    "top99 = np.where(cumulative_sum > 0.99)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_sum(cumulative_sum, top90, top95, top99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train_95 = transformed_train\n",
    "transformed_train_95[:,top95+1:] = 0\n",
    "print(transformed_train_95.shape)\n",
    "\n",
    "transform_top95_generate = pca.inverse_transform(transformed_train_95)\n",
    "print(transform_top95_generate.shape)\n",
    "\n",
    "fig = plt.figure(figsize=[20, 8])\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(4, 10, 2*i + 1)\n",
    "    ax.imshow(np.reshape(train_PCA[i,:], (N,N)))\n",
    "    ax.set_title('Original')\n",
    "    ax.axis('off')\n",
    "    ax = fig.add_subplot(4, 10, 2*i + 2)\n",
    "    pc = np.reshape(transform_top95_generate[i,:], (N, N)) \n",
    "    ax.imshow(pc)\n",
    "    ax.set_title('PCA')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose to use 95% recreation\n",
    "transformed_train_95 = transformed_train[:, 0:top95]\n",
    "transformed_val_95 = transformed_val[:, 0:top95]\n",
    "transformed_test_95 = transformed_test[:, 0:top95]\n",
    "\n",
    "print(transformed_train_95.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "lda.fit(np.array(transformed_train_95), np.array(train_y))\n",
    "\n",
    "transformed_train_LDA = lda.transform(transformed_train_95)\n",
    "transformed_val_LDA = lda.transform(transformed_val_95)\n",
    "transformed_test_LDA = lda.transform(transformed_test_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(transformed_train_LDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_hyperparams(model, params, X_train, Y_train, X_validate, Y_validate):\n",
    "    # Create list of all possible combinations\n",
    "    param_list = list(ParameterGrid(params))\n",
    "    \n",
    "    # Initialising \n",
    "    best_result = 0.00;\n",
    "    best_params = param_list[0];\n",
    "    worst_result = 1.00;\n",
    "    worst_params = param_list[0];\n",
    "    # looping through all parameters in parameter list\n",
    "    for params in param_list:\n",
    "        # creating model with set parameters\n",
    "        model = model.set_params(**params)\n",
    "        # training the model\n",
    "        model.fit(X_train, Y_train)\n",
    "        # retrieving model score\n",
    "        result = model.score(X_validate, Y_validate)\n",
    "        # checking if model score is better, then allocating best parameters\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_params = params\n",
    "        if result < worst_result:\n",
    "            worst_result = result\n",
    "            worst_params = params\n",
    "    \n",
    "    # Return the best\n",
    "    print(best_params)\n",
    "    print(\"Validation Accuracy \" + str(best_result))\n",
    "    print(worst_params)\n",
    "    print(\"Validation Accuracy \" + str(worst_result))\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'class_weight': ['balanced'], 'decision_function_shape': ['ovo', 'ovr'], 'C': list(range(1, 30)), 'gamma': [0.00005, 0.0001, 0.0003, 0.0005], 'kernel' : ['rbf', 'sigmoid']}\n",
    "\n",
    "# Find Optimal Hyperparameters and then create model\n",
    "model = SVC()\n",
    "best_params2 = search_hyperparams(model, param_grid, transformed_train_LDA, train_y, transformed_val_LDA, val_y)\n",
    "\n",
    "svm = model.set_params(**best_params2)\n",
    "svm.fit(transformed_train_LDA, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, X_train, Y_train, X_test, Y_test):\n",
    "    labels = ['No Tumour', 'Glioma', 'Meningioma', 'Pituitary']\n",
    "    fig = plt.figure(figsize=[25, 8])\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    conf = ConfusionMatrixDisplay.from_estimator(model, X_train, Y_train, normalize='true', ax=ax, display_labels=labels)\n",
    "    #conf.ax_.set_title('Training Set Performance: %1.3f' % (sum(model.predict(X_train) == Y_train)/len(Y_train)));\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    conf = ConfusionMatrixDisplay.from_estimator(model, X_test, Y_test, normalize='true', ax=ax, display_labels=labels)\n",
    "    #conf.ax_.set_title('Testing Set Performance: %1.3f' % (sum(model.predict(X_test) == Y_test)/len(Y_test)));\n",
    "    print(classification_report(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(svm, transformed_train_LDA, train_y, transformed_test_LDA, test_y)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
